{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project milestone 4\n",
    "Tadaa - Jonathan Haenni, Lea Schmidt, Danny Kohler\n",
    "> This work presents the creative extension of the publication from J. Penney : \"Chilling effects : Online surveillance and Wikipedia use\".\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "The goal of this work is to observe if the public action of Greta Thunberg and her continual incitation for people to educate themselves on the subject of climate change has actually made a difference. This effect would be diametrically different from a chilling effect in that it pushes people to get educated on a subject, effectively arguably increasing their levels of freedom. This effect shall henceforth be called an \"Empowering effect\".\n",
    "\n",
    "First and foremost, the selected interest period depends on the choice of events that will be the pivots of the interrupted time series analysis. (ITS) These events are as follows: the school strike of August 20, 2018 led by Greta Thunberg, the 2018 United Nations Climate Change Conference (COP24) on December 14, 2018 and the summit of the United Nations on September 23, 2019. The period of analysis is between January 2018 and February 2020. As seen in HW1, the Covid-19 pandemic influences the pageviews a lots and we will therefore not elongate this analysis onto 2020.\n",
    "\n",
    "The data considered here comes from Wikipedia. We will consider 150 [ADAPT VALUE] Wikipedia articles divided into 3 groups. The first group is the treatment dataset, containing the Wikipedia articles related to climate change issues. The second group is a quasi-control group, where the topics considered are related to nature, without being related to climate change directly. The third group is another control group composed of popular articles simply reflecting the trends on Wikipedia. It is the same as the one used in the publication. The data sets considered give the number of pageviews per day for each article, within the time period considered.\n",
    "\n",
    "As already hinted at, the analysis will be very similar to the one used in the publication - an ITS analysis with segmented linear regressions.\n",
    "\n",
    "If the first group features significant changes in pageviews and the control groups don't across the selected period, we will be able to conclude that the \"Empowering Effect\" exists and we will be able to compare it to the chilling effect considered in the publication.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data loading and filtering\n",
    "\n",
    "> code description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the climate change articles data\n",
    "art_cc1 = pd.read_csv('data/pageviews-10-pro.csv').copy()\n",
    "art_cc2 = pd.read_csv('data/pageviews-20-pro.csv').copy()\n",
    "art_cc3 = pd.read_csv('data/pageviews-30-pro.csv').copy()\n",
    "art_cc4 = pd.read_csv('data/pageviews-40-pro.csv').copy()\n",
    "art_cc5 = pd.read_csv('data/pageviews-50-pro.csv').copy()\n",
    "\n",
    "# Load the control (popular) articles data\n",
    "art_control1 = pd.read_csv('data/pageviews-10-control.csv').copy()\n",
    "art_control2 = pd.read_csv('data/pageviews-20-control.csv').copy()\n",
    "art_control3 = pd.read_csv('data/pageviews-30-control.csv').copy()\n",
    "art_control4 = pd.read_csv('data/pageviews-40-control.csv').copy()\n",
    "#art_control5 = pd.read_csv('data/pageviews-50-control.csv').copy()\n",
    "\n",
    "# Merge all datasets together\n",
    "art_cc=art_cc1.merge(art_cc2).merge(art_cc3).merge(art_cc4).merge(art_cc5)\n",
    "art_control=art_control1.merge(art_control2).merge(art_control3).merge(art_control4)#.merge(art_control5)\n",
    "\n",
    "# Display to illustrate the structure\n",
    "art_control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Translate dates in datetime type\n",
    "# art_cc.Date=pd.to_datetime(art_cc.Date)\n",
    "# art_control.Date=pd.to_datetime(art_control.Date)\n",
    "\n",
    "# # Set the date as the index\n",
    "# art_cc=art_cc.set_index('Date')\n",
    "# art_control=art_control.set_index('Date')\n",
    "\n",
    "# # Agregate the data by months\n",
    "# art_cc=art_cc.groupby(pd.Grouper(freq=\"M\")).sum()\n",
    "# art_control=art_control.groupby(pd.Grouper(freq=\"M\")).sum()\n",
    "\n",
    "# # Display to illustrate the structure\n",
    "# display(art_control.head())\n",
    "\n",
    "# # At this point, we should  sum over all articles.\n",
    "# art_cc=art_cc.sum(axis=1)\n",
    "# art_control=art_control.sum(axis=1)\n",
    "\n",
    "# # Here the index is reset to get the number of months instead of dates, as in the publication.\n",
    "# # The date column is then removed : it is not needed anymore\n",
    "# # The pageviews column is renamed\n",
    "# art_cc=art_cc.reset_index()\n",
    "# art_cc=art_cc.drop('Date', axis=1)\n",
    "# art_cc.columns=['pageviews']\n",
    "\n",
    "# art_control=art_control.reset_index()\n",
    "# art_control=art_control.drop('Date', axis=1)\n",
    "# art_control.columns=['pageviews']\n",
    "\n",
    "# # Display to illustrate the structure\n",
    "# display(art_control.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Here we have a function to aggregate the dataframe. It creates a dataframe with the index as the datetimes by month and with two columns as the number of the month and the pageviews count over all the article during the said month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je propose cette fonction pour aggrÃ©ger directement mais en pouvant choisir quel article drop \n",
    "#s'il y a des outliers. En plus les dates sont en index ce qui permet d'utiliser les features de Pandas\n",
    "\n",
    "def aggregate(df, freq=\"M\", drop = None) :\n",
    "    \"\"\"A function to aggregate the dataframe as a Serie sorted by month\n",
    "    with the total number of pageviews per month. With the numbering of each\n",
    "    month of the timeserie. drop is used to drop a list of articles in the \n",
    "    dataframe. freq is used to choice the frequency of the aggregation. Return the dataframe\"\"\"\n",
    "    df=df.copy()\n",
    "    df.index=df.Date\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    df=df.drop(columns=\"Date\")\n",
    "    #Recreate the dataframe without the named articles\n",
    "    if not drop == None :\n",
    "        df=df.drop(columns=drop)\n",
    "    \n",
    "    # At this point, we should  sum over all articles.\n",
    "    df=df.sum(axis=1)\n",
    "    # Agregate the data by months\n",
    "    df=df.groupby(pd.Grouper(freq=freq)).sum()\n",
    "    #Serie to dataframe\n",
    "    df=df.to_frame()\n",
    "    #Rename the column\n",
    "    df.columns=['pageviews']\n",
    "    #Add the column months to help to plot with the regression\n",
    "    months=np.arange(1, len(df.index)+1)\n",
    "    df[\"months\"]=months\n",
    "    return df\n",
    "\n",
    "art_control_agg=aggregate(df=art_control)\n",
    "art_cc_agg=aggregate(df=art_cc)\n",
    "\n",
    "display(art_control_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Computing the Segmented Regression parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Here we define all the intervals between the mentioned event about the climate : the school strike of August 20, 2018 led by Greta Thunberg and the 2018 United Nations Climate Change Conference (COP24) on December 14, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVALS =[[\"2018-01\",\"2018-07\"],[\"2018-08\",\"2018-07\"],[\"2018-01\",\"2018-07\"],[\"2018-01\",\"2018-07\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import datetime\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "\n",
    "def list_LR_periods(df, before_interval=[\"2012-01\",\"2013-05\"], after_interval=[\"2013-06\",\"2014-08\"], CI=0.05) :\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    #Linear regression before June 2013  \n",
    "    mod_before = smf.ols(formula=\"pageviews ~ months\", data=df.loc[before_interval[0]:before_interval[1]])\n",
    "    res_before=mod_before.fit()\n",
    "    #Compute the serie of predicted values from the basic linear equation with one variable : y = intercept + coef * x\n",
    "    pages_predict_before=res_before.params[0]+res_before.params[1]*df.loc[before_interval[0]:before_interval[1]][\"months\"]\n",
    "    #Extract the computed values (including upper and lower CI values)\n",
    "    _, summary_values_before, summary_names_before = summary_table(res_before, alpha=CI)\n",
    "    #Create a temporary dataframe with the result\n",
    "    df_res_tmp = pd.DataFrame(summary_values_before, columns=summary_names_before)\n",
    "    display(df_res_tmp)\n",
    "    #WARNING : It's a bit tricky but the column has always 95% in its name even if the CI\n",
    "    #introduce in alpha is different of 0.05. It has been tested and the values are different.\n",
    "#     predict_ci_low_before = df_res_tmp[\"Predict ci\\n95% low\"].T\n",
    "#     predict_ci_upp_before = df_res_tmp[\"Predict ci\\n95% upp\"].T\n",
    "    predict_ci_low_before = df_res_tmp[\"Mean ci\\n95% low\"].T\n",
    "    predict_ci_upp_before = df_res_tmp[\"Mean ci\\n95% upp\"].T\n",
    "\n",
    "    #Linear regression after June 2013\n",
    "    mod_after = smf.ols(formula=\"pageviews ~ months\", data=df.loc[after_interval[0]:after_interval[1]])\n",
    "    res_after=mod_after.fit()\n",
    "    #Compute the serie of predicted values from the basic linear equation with one variable : y = intercept + coef * x\n",
    "    pages_predict_after=res_after.params[0]+res_after.params[1]*df.loc[after_interval[0]:after_interval[1]][\"months\"]\n",
    "    #Extract the computed values (including upper and lower CI values)\n",
    "    _, summary_values_after, summary_names_after = summary_table(res_after, alpha=CI)\n",
    "    #Create a temporary dataframe with the result\n",
    "    df_res_tmp = pd.DataFrame(summary_values_after, columns=summary_names_after)\n",
    "#     predict_ci_low_after = df_res_tmp[\"Predict ci\\n95% low\"].T\n",
    "#     predict_ci_upp_after = df_res_tmp[\"Predict ci\\n95% upp\"].T\n",
    "    predict_ci_low_after = df_res_tmp[\"Mean ci\\n95% low\"].T\n",
    "    predict_ci_upp_after = df_res_tmp[\"Mean ci\\n95% upp\"].T\n",
    "    \n",
    "    #Create a dictionnary to pass the results\n",
    "    dic = {\n",
    "        \"before\" :{\n",
    "            \"result\" : res_before,\n",
    "            \"predicts\" : pages_predict_before,\n",
    "            \"CI\" : {\n",
    "                \"lower\" : predict_ci_low_before,\n",
    "                \"upper\" : predict_ci_upp_before\n",
    "            }\n",
    "        }, \n",
    "        \"after\" : {\n",
    "            \"result\" : res_after,\n",
    "            \"predicts\" : pages_predict_after,\n",
    "            \"CI\" : {\n",
    "                \"lower\" : predict_ci_low_after,\n",
    "                \"upper\" : predict_ci_upp_after\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Displaying the results\n",
    "\n",
    "> code description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada_test_2] *",
   "language": "python",
   "name": "conda-env-ada_test_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
